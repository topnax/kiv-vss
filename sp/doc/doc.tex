\documentclass[12pt, a4paper]{article}

\usepackage[english]{babel}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[pdftex]{graphicx}
\usepackage{amsmath, amssymb}
\usepackage[hidelinks,unicode]{hyperref}
\usepackage{float}
\usepackage{listings}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage[final]{pdfpages}
\usepackage{syntax}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsfonts}
\usepackage{wrapfig}


\definecolor{mauve}{rgb}{0.58,0,0.82}
\usetikzlibrary{shapes,positioning,matrix,arrows}

\newcommand{\img}[1]{(see figure \ref{#1})}
\newcommand\todo[1]{\textcolor{red}{#1}}

\definecolor{pblue}{rgb}{0.13,0.13,1}
\definecolor{pgreen}{rgb}{0,0.5,0}
\definecolor{pred}{rgb}{0.9,0,0}
\definecolor{pgrey}{rgb}{0.46,0.45,0.48}


\lstdefinestyle{flex}{
    frame=tb,
    aboveskip=3mm,
    belowskip=3mm,
    showstringspaces=false,
    columns=flexible,
    basicstyle={\small\ttfamily},
    numbers=none,
    numberstyle=\tiny\color{black},
    keywordstyle=\color{black},
    commentstyle=\color{black},
    stringstyle=\color{black},
    breaklines=true,
    breakatwhitespace=true,
    tabsize=3
}

\lstset{
    frame=tb,
    language=Python,
    aboveskip=3mm,
    belowskip=3mm,
    showstringspaces=false,
    columns=flexible,
    basicstyle={\small\ttfamily},
    numbers=none,
    numberstyle=\tiny\color{gray},
    keywordstyle=\color{blue},
    commentstyle=\color{pgreen},
    stringstyle=\color{mauve},
    breaklines=true,
    breakatwhitespace=true,
    tabsize=3
}


\let\oldsection\section
\renewcommand\section{\clearpage\oldsection}

\begin{document}
	% this has to be placed here, after document has been created
	% \counterwithout{lstlisting}{chapter}
	\renewcommand{\lstlistingname}{Ukázka kódu}
	\renewcommand{\lstlistlistingname}{Seznam ukázek kódu}
    \begin{titlepage}

        \centering

        \vspace*{\baselineskip}
        \begin{figure}[H]
        \centering
        \includegraphics[width=7cm]{img/fav-logo.jpg}
        \end{figure}

        \vspace*{1\baselineskip}

        \vspace{0.75\baselineskip}

        \vspace{0.5\baselineskip}
        {KIV/VSS Semester Project}

        {\LARGE\sc Benchmarking A Payment Terminal Managemenent Server \\}

        \vspace{4\baselineskip}

        \vspace{0.5\baselineskip}

        {\sc\Large Stanislav Král \\}
        \vspace{0.5\baselineskip}
        {A20N0091P}

        \vfill

        {\sc Západočeská univerzita v Plzni\\
        Fakulta aplikovaných věd}

    \end{titlepage}

    % TOC
    \tableofcontents
    \pagebreak

\section{Tools for benchmarking web applications}\label{intro}

With the number of people with access to the Internet continuously rising the usage load of web applications is obviously rising too and the need for scalable web technologies and architectures is higher than ever.
While today's web developers are aware of this they are also in need of tools that are able to measure application's performance and to discover its possible limits.

Many free and paid tools for benchmarking web applications are available today.
One example of such free tool is Apache's open-source program \textbf{ab} (also known as ApacheBench) that has been available since 1996 and was originally used to test the Apache HTTP Server.
However, it's generic enough to test any web server supporting HTTP protocols.
One of its main disadvantages is the fact that it allows tests to be run only in one thread which limits concurrency and may create bottlenecks.
This problem can be overcome by running multiple instances of the program.

Shortly after the release of ApacheBench Apache releases another tool for benchmarking web applications -- \textbf{Apache JMeter}.
Unlike its predecessor Apache JMeter comes with a rich GUI and feature set and is capable of measuring the performance not only of HTTP servers but also of other services such as JDBC database connections, FTP, LDAP or JMS.
Out of the box it supports test parametrization, response validation, per-thread cookies, integration with the Selenium test framework and variety of useful reports.
JMeter architecture is focused around plugins and missing features not present in the base version of the program are added via official or community plugins.

With the promise of making the process of defining and writing load tests simpler and more intiutive for developers the open-source load testing tool \textbf{k6} is released in 2016.
It is used for testing the performance and realiability of web APIs, microservices and websites.
When using this tool developers use the Javascript language to write benchmark scenarios, where each simulated user (that makes request to the application put under a test) is represented by a Virtual User entity and its behaviour can be defined in a single Javascript method.
The number of users can be easily defined in such way that it will be changing during the test as needed by the test scenario (e.g., linear growth in the first 60 seconds followed by a constant number of users).
Once the test is finished the user is presented with a brief summary containing useful stats such as the average duration of each stage of performed HTTP requests.
In addition to the tool the team behind it offers a paid online service that allows for running load tests from the cloud with the possibility of creating advanced reports an summaries.
Even though running the tool locally is sufficient for most of the time and enough stress can be put on the tested server the reports of tests are missing some important information such as a chart with the average server response time during the test.
Luckily the tool makes it possible to serialize all events that occur during the test to a JSON file.
Such file can be then processed by our own software in order to find missing information. 


\section{Automatization of terminal management}

As introduced in the assignment of this semester project the web application to be put under the test is the Dotypay Portal site that is used for the management of Dotypay payment terminals.

For the purpose of running benchmarks the Dotypay Portal development team has prepared a dedicated application instance running on the same configuration as the production instance.
However, the application's data in the instance to be tested were copied from the development environment.
This means that it was required to generate and submit additional data to the instance as it was excepted that the number of terminals present in the database (about 250 terminals)  would not be enough for putting enough stress on the server.

Because the server does not expose a REST API for creating new terminals the only way of filling the database with more data was to login into the application, go to the page where the form for creating new terminals is located and fill in individual terminal data. 
The initial goal was to have at least two thousand terminals present in the database.
Adding this many terminals manually would be close to unfeasable and a need for task automatization emerged.


\subsection{Writing an automatization script in Python}

Since the author of this semester project had previous experience with testing web applications using the Python language and the Playwright library\footnote{\url{https://playwright.dev/}} he chose write an automatization script using them.

It was soon discovered that not only the creation of terminals was required, but so was their activation, since only after terminals are activated they can communicate with the server using a unique API key that is assigned to them.

After a quick analysis of the application's UI interface and it's REST API (documented using OpenAPI specification) a Python script was created, that automates the process of logging in and creating a desired number of terminals.
Another feature of the script is that all terminals specified by a range of identifiers are activated.
The process of activation may include deactivation that is done using the UI interface and a REST API call that, if successful, yields an API key.


\subsection{Gathering terminal data}

Before running any benchmarks it was not only required to have a set of all terminal API keys of terminals present in the database but also to have other terminal data, such as their ID or serial number because it was required by some API calls present in test scenarios.
Even though this data could be accessed from the application's UI it would require another automatization script.
Because of that the author of this semester project was granted an access and login credentials to the instance's MS SQL database from which, using a simple SQL query, he was able to fetch all required data when needed.


\section{Benchmark scenarios}

In order to be able to measure application's ability to handle a higher amount of terminals it was required to prepare one or more benchmark scenarios that attempt to simulate real terminal behaviour.


\subsection{Terminal synchronization}
All terminals periodically perform a synchronization with the Dotypay portal.
This behaviour was described in the assignment but after further analysis of the Dotypay Payment Terminal application's source code it was soon discovered that the original description was quite shallow and the whole process of terminal synchronization involves more steps.
Synchronization consists of calling Dotypay Portal API endpoints in the following order:

\begin{itemize}
    \item \texttt{files} endpoint -- an endpoint that returns all files that the terminal should download (may involve any important documents or other files),
    \item \texttt{status} endpoint -- an endpoint that is used to report the status of the terminal to the server,
    \item \texttt{tasks} endpoint -- an endpoint that returns tasks (apply new terminal configuration or upload required files) filtered by their status (\texttt{CREATED}, \texttt{RECEIVED}, \texttt{IN\_PROGRESS}),
    \item and \texttt{apps} endpoint -- an endpoint that returns links to all APK files (Android application package file) to be downloaded and installed by the terminal filtered by their type (Launcher Application package, mandatory applications or optional applications).
\end{itemize}

Once terminal performs a synchronization it waits for a random duration of time ranging from 9 to 11 minutes before performing another synchronization.

\todo{Make sure constraints are correct}

The aim is to simulate at least 10 000 terminals periodically performing synchronization for the duration of 2 hours.

\subsection{Submission of performed transactions}

\todo{Add description}


\section{Benchmark scenario implementation with k6}

\todo{TBD}


\section{Test results visualization}

As mentioned in section \ref{intro} the k6 tool does not allow for creating charts visualizing test results data when run locally.
This results in inability to easily see how does the server response time change during the test.
To overcome this issue the author has decided to create a simple script in Python and with the use of the \texttt{matplotlib} library plot visualize the data produced by k6.

\begin{figure}[!ht]
    \centering 
    \includegraphics[width=1\textwidth]{pdf/visualizer-example.pdf}
    \caption{An example chart produced by the visualization script}
\end{figure}

Such visualization is possible because k6 tool supports exporting test results data to a JSON file by passing the argument \texttt{--out json=<file\_name>} to it.

Before the visualization can be done the JSON file containing test results has to be processed.
Each line of the file contains a JSON object containing either a metric definition or a measurement.
Developer can define custom metrics or use one of those that come predefined with the tool\footnote{\url{https://k6.io/docs/using-k6/metrics/#http-specific-built-in-metrics}}.

After all measurement objects have been parsed and processed a plot using the \texttt{matplotlib} library can be displayed.
The script also allows for exporting the created chart into a SVG file.

Due to the lack of free k6 test results visualization tools publicly available the author has decided to publish this script on GitHub \todo{repo link}.



\end{document}
